# Pipeline_ETL_Simples

Este projeto Ã© um exemplo de **pipeline ETL (Extract, Transform, Load)** simples, desde a geraÃ§Ã£o de um dataset fictÃ­cio atÃ© a anÃ¡lise de dados.  
O objetivo Ã© demonstrar o fluxo completo de dados, manipulaÃ§Ã£o com Python e criaÃ§Ã£o de visualizaÃ§Ãµes.

---

## ğŸ—‚ Estrutura do RepositÃ³rio

Pipeline_ETL_Simples/
Data/
        â””â”€ vendas.db # Dataset gerado
        â””â”€â”€ banco_vendas.db # Banco SQLite gerado pelo ETL
notbooks/ 
        â””â”€01_Pipeline_ETL_Simples.ipynb # Pipeline ETL completo
         â””â”€ 02_Analise_Vendas.ipynb # Consultas SQL e grÃ¡ficos
         â””â”€â”€ 03_analise_dados.ipynb # AnÃ¡lise de dados: EDA, grÃ¡ficos e insights
README.md

---

## **ğŸ›  Tecnologias utilizadas**

- **Python** â€“ manipulaÃ§Ã£o de dados e scripts ETL  
- **pandas** â€“ tratamento e anÃ¡lise de dados  
- **sqlite3** â€“ armazenamento de dados em banco SQLite  
- **Matplotlib / Seaborn** â€“ visualizaÃ§Ã£o de dados  
- **Google Colab** â€“ ambiente de desenvolvimento  

---

## **ğŸ“Œ DescriÃ§Ã£o dos notebooks**

### 1ï¸âƒ£ 01_geracao_dataset.ipynb
- Cria um dataset fictÃ­cio de vendas com colunas como `produto`, `preco`, `quantidade` e `data_venda`  
- Salva o dataset em CSV (`data/vendas.csv`)  

### 2ï¸âƒ£ 02_pipeline_ETL.ipynb
- Carrega o CSV do notebook anterior  
- Realiza transformaÃ§Ãµes e limpeza (remover duplicados, ajustar tipos de dados)  
- Salva os dados transformados em um **banco SQLite** (`data/banco_vendas.db`)  

### 3ï¸âƒ£ 03_analise_dados.ipynb
- Conecta ao banco SQLite e carrega os dados em um DataFrame  
- Faz **anÃ¡lise exploratÃ³ria** (EDA): linhas, colunas, tipos de dados, valores nulos, estatÃ­sticas descritivas  
- Cria grÃ¡ficos e visualizaÃ§Ãµes:  
  - DistribuiÃ§Ã£o de preÃ§os  
  - Total de vendas por produto  
  - EvoluÃ§Ã£o de vendas ao longo do tempo  
- Salva os grÃ¡ficos como imagens (`.png`) para portfÃ³lio ou redes sociais  

---

## **âš¡ Como executar o projeto**

1. Abra o **Google Colab** ou seu ambiente local  
2. Abra e execute os notebooks na ordem:  
3. Verifique se a pasta `data/` contÃ©m o CSV e o banco SQLite  
4. Os grÃ¡ficos gerados serÃ£o exibidos no notebook e tambÃ©m podem ser salvos como imagens  

---

## **ğŸ“Š Objetivo do projeto**

- Demonstrar **pipeline ETL completo** de dados fictÃ­cios  
- Mostrar capacidade de:  
- Gerar datasets realistas  
- Limpar e transformar dados  
- Criar banco de dados para anÃ¡lise  
- Gerar visualizaÃ§Ãµes e insights  
- Servir como **portfÃ³lio** para vagas em **engenharia de dados** ou anÃ¡lise de dados  

---

## **ğŸ“Œ ObservaÃ§Ãµes**

- O projeto foi feito de forma **didÃ¡tica e simples**, ideal para estudantes e iniciantes em ETL e anÃ¡lise de dados  
- Todos os caminhos de arquivos estÃ£o centralizados na pasta `data/` para organizaÃ§Ã£o  

---


